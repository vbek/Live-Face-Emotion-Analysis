{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# -------------------------\n",
    "# Helpers & Resource Paths\n",
    "# -------------------------\n",
    "def resource_path(relative_path):\n",
    "    try:\n",
    "        base_path = sys._MEIPASS\n",
    "    except Exception:\n",
    "        base_path = os.path.abspath(\".\")\n",
    "    return os.path.join(base_path, relative_path)\n",
    "\n",
    "# Import models\n",
    "from emotion_classification.models.cnn import CNN\n",
    "from emotion_classification.models.resnet_vanilla import LightweightResNet\n",
    "from emotion_classification.models.resnet18 import ResNet18Emotion\n",
    "\n",
    "# -------------------------\n",
    "# Detection & Device Setup\n",
    "# -------------------------\n",
    "from ultralytics import YOLO\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "YOLO_MODEL_PATH = resource_path(\"./face_detection/yolo/yolov8n_face_detection/weights/best.pt\")\n",
    "face_detector = YOLO(YOLO_MODEL_PATH)\n",
    "face_detector.to(DEVICE)\n",
    "\n",
    "# -------------------------\n",
    "# Emotion Model Configuration\n",
    "# -------------------------\n",
    "num_classes = 4\n",
    "EMOTIONS = [\"Angry\", \"Happy\", \"Sad\", \"Surprise\"]\n",
    "BASE_MODEL_DIR = resource_path(\"./emotion_classification\")\n",
    "\n",
    "MODEL_INFO = {\n",
    "    \"CNN\": (CNN, os.path.join(BASE_MODEL_DIR, \"checkpoints_cnn/best.pth\")),\n",
    "    \"ResNet18\": (ResNet18Emotion, os.path.join(BASE_MODEL_DIR, \"checkpoints_resnet18/best.pth\")),\n",
    "    \"Resnet_Vanilla\": (LightweightResNet, os.path.join(BASE_MODEL_DIR, \"checkpoints_resnet_vanilla/best.pth\")),\n",
    "}\n",
    "\n",
    "loaded_models = {}\n",
    "\n",
    "def safe_load_weights(model, ckpt_path):\n",
    "    model.to(DEVICE)\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"[Warning] Checkpoint not found: {ckpt_path}\")\n",
    "        return model\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=True)\n",
    "    state = ckpt.get(\"model_state\", ckpt)\n",
    "    try:\n",
    "        model.load_state_dict(state)\n",
    "    except:\n",
    "        model.load_state_dict(state, strict=False)\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name in loaded_models:\n",
    "        return loaded_models[model_name]\n",
    "\n",
    "    constructor, ckpt_path = MODEL_INFO[model_name]\n",
    "    model = constructor(num_classes)\n",
    "    model = safe_load_weights(model, ckpt_path)\n",
    "    loaded_models[model_name] = model\n",
    "    return model\n",
    "\n",
    "def preprocess_face(face_img, model_name):\n",
    "    # ResNet18 trained on 224, CNN/Vanilla trained on 96\n",
    "    size = 224 if model_name == \"ResNet18\" else 96\n",
    "    img = cv2.resize(face_img, (size, size))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(DEVICE) / 255.0\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Main Application GUI\n",
    "# -------------------------\n",
    "class EmotionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Face & Emotion Detection\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "\n",
    "        # UI Elements\n",
    "        self.selected_model = tk.StringVar(value=\"CNN\")\n",
    "        self.model_menu = ttk.Combobox(root, textvariable=self.selected_model, values=list(MODEL_INFO.keys()))\n",
    "        self.model_menu.pack(pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(root, bg=\"black\")\n",
    "        self.canvas.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        # Video Capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.update_frame()\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(30, self.update_frame)\n",
    "            return\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # 1. Detect Faces\n",
    "        results = face_detector(frame, verbose=False)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "        # 2. Process each detected face\n",
    "        for x1, y1, x2, y2 in boxes:\n",
    "            face_img = frame[y1:y2, x1:x2]\n",
    "            if face_img.size == 0: continue\n",
    "\n",
    "            model_name = self.selected_model.get()\n",
    "            model = get_model(model_name)\n",
    "            input_tensor = preprocess_face(face_img, model_name)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(input_tensor)\n",
    "                logits = out[0] if isinstance(out, tuple) else out\n",
    "                pred = torch.argmax(logits, dim=1).item()\n",
    "                conf = torch.softmax(logits, dim=1)[0, pred].item()\n",
    "                label = f\"{EMOTIONS[pred]} ({conf:.2f})\"\n",
    "\n",
    "            # Draw results on frame\n",
    "            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # 3. Render to Tkinter Canvas\n",
    "        img_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "        self.img_tk = ImageTk.PhotoImage(img_pil)\n",
    "        self.canvas.create_image(0, 0, anchor=tk.NW, image=self.img_tk)\n",
    "        \n",
    "        self.root.after(10, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = EmotionApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
